{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aab680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcluzeau/miniconda3/envs/env_proj_court/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répertoire courant : /home/gcluzeau/Zone_de_travail/projet_court\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from einops import rearrange\n",
    "from MDAnalysis.analysis.dssp import DSSP \n",
    "import MDAnalysis as mda\n",
    "\n",
    "# Remplace par le chemin que tu veux\n",
    "os.chdir(\"/home/gcluzeau/Zone_de_travail/projet_court\")\n",
    "\n",
    "# Vérifie que ça a marché\n",
    "print(\"Répertoire courant :\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ff75d",
   "metadata": {},
   "source": [
    "Detection des structure secondaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598969df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdb_residues(pdb_path):\n",
    "    \"\"\"\n",
    "    Parse residues from a PDB file, extracting atom coordinates for N, CA, C, O, H, and H1 atoms.\n",
    "    Returns a dictionary of residues with atom coordinates.\n",
    "    \"\"\"\n",
    "    residues = {}\n",
    "    with open(pdb_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if not line.startswith(\"ATOM\"):\n",
    "                continue\n",
    "\n",
    "            # Extract relevant fields from fixed-width PDB format\n",
    "            atom_name = line[12:16].strip()\n",
    "            resname = line[17:20].strip()\n",
    "            chain_id = line[21].strip()\n",
    "            resseq = int(line[22:26])\n",
    "\n",
    "            x = float(line[30:38])\n",
    "            y = float(line[38:46])\n",
    "            z = float(line[46:54])\n",
    "\n",
    "            key = (chain_id, resseq)\n",
    "            if key not in residues:\n",
    "                residues[key] = {'resname': resname}\n",
    "\n",
    "            # Store only backbone atoms and possible hydrogens\n",
    "            if atom_name in {'N', 'CA', 'C', 'O', 'H', 'H1'}:\n",
    "                residues[key][atom_name] = [x, y, z]\n",
    "\n",
    "    return residues\n",
    "\n",
    "\n",
    "def _get_hydrogen_atom_position(residue_keys, j, residues_dict):\n",
    "    \"\"\"\n",
    "    Estimate the hydrogen (H) atom position of residue j using neighboring atom vectors.\n",
    "    Returns None if required atoms are missing.\n",
    "    \"\"\"\n",
    "    if j == 0:\n",
    "        return None\n",
    "\n",
    "    prev_key = residue_keys[j - 1]\n",
    "    curr_key = residue_keys[j]\n",
    "\n",
    "    res_prev = residues_dict.get(prev_key, {})\n",
    "    res_curr = residues_dict.get(curr_key, {})\n",
    "\n",
    "    N = res_curr.get('N')\n",
    "    CA = res_curr.get('CA')\n",
    "    C_prev = res_prev.get('C')\n",
    "\n",
    "    if None in (N, CA, C_prev):\n",
    "        return None\n",
    "\n",
    "    # Calculate normalized vectors and estimate H position\n",
    "    N = np.array(N)\n",
    "    CA = np.array(CA)\n",
    "    C_prev = np.array(C_prev)\n",
    "\n",
    "    vec_cn = N - C_prev\n",
    "    vec_cn /= np.linalg.norm(vec_cn)\n",
    "\n",
    "    vec_can = N - CA\n",
    "    vec_can /= np.linalg.norm(vec_can)\n",
    "\n",
    "    vec_nh = vec_cn + vec_can\n",
    "    vec_nh /= np.linalg.norm(vec_nh)\n",
    "\n",
    "    return (N + 1.01 * vec_nh).tolist()\n",
    "\n",
    "\n",
    "def distance_atom(atom1, atom2):\n",
    "    \"\"\"\n",
    "    Compute Euclidean distance between two atoms, return inf if either is missing.\n",
    "    \"\"\"\n",
    "    if atom1 is None or atom2 is None:\n",
    "        return float('inf')\n",
    "    return np.linalg.norm(np.array(atom1) - np.array(atom2))\n",
    "\n",
    "\n",
    "def is_hydrogen_bond(res_1, res_2, j, residue_keys, residues_dict):\n",
    "    \"\"\"\n",
    "    Determine if a hydrogen bond exists between two residues using an electrostatic energy approximation.\n",
    "    \"\"\"\n",
    "    # Try to get hydrogen atom position (explicit or estimated)\n",
    "    h_atom_coords = res_2.get('H') or res_2.get('H1')\n",
    "    if h_atom_coords is None:\n",
    "        h_atom_coords = _get_hydrogen_atom_position(residue_keys, j, residues_dict)\n",
    "        if h_atom_coords is None:\n",
    "            return False\n",
    "\n",
    "    # Compute distances needed for electrostatic energy calculation\n",
    "    d_oh = distance_atom(res_1.get('O'), h_atom_coords)\n",
    "    d_ch = distance_atom(res_1.get('C'), h_atom_coords)\n",
    "    d_on = distance_atom(res_1.get('O'), res_2.get('N'))\n",
    "    d_cn = distance_atom(res_1.get('C'), res_2.get('N'))\n",
    "\n",
    "    if float('inf') in {d_on, d_oh, d_cn, d_ch}:\n",
    "        return False\n",
    "\n",
    "    # Electrostatic energy approximation\n",
    "    q1 = 0.42\n",
    "    q2 = 0.20\n",
    "    f = 332\n",
    "    Emin = -0.5\n",
    "    E_elec = q1 * q2 * f * (1 / d_on + 1 / d_ch - 1 / d_oh - 1 / d_cn)\n",
    "\n",
    "    return E_elec < Emin\n",
    "\n",
    "\n",
    "def find_beta_bridges(residues_dict):\n",
    "    \"\"\"\n",
    "    Identify beta-sheet hydrogen bonding patterns and classify them as parallel or antiparallel.\n",
    "    \"\"\"\n",
    "    residue_keys = sorted(residues_dict.keys())\n",
    "    bridges = {}\n",
    "    n = len(residue_keys)\n",
    "\n",
    "    for i in range(n - 1):\n",
    "        for j in range(i + 2, n):  # Avoid neighbors (i+1)\n",
    "            res_i = residues_dict[residue_keys[i]]\n",
    "            res_j = residues_dict[residue_keys[j]]\n",
    "\n",
    "            # Check for antiparallel bridge\n",
    "            if is_hydrogen_bond(res_i, res_j, j, residue_keys, residues_dict) and \\\n",
    "               is_hydrogen_bond(res_j, res_i, i, residue_keys, residues_dict):\n",
    "                bridges[(residue_keys[i], residue_keys[j])] = 'antiparallel'\n",
    "\n",
    "            # Check for parallel bridge\n",
    "            elif j + 1 < n and i + 1 < n:\n",
    "                res_jp1 = residues_dict[residue_keys[j + 1]]\n",
    "                res_ip1 = residues_dict[residue_keys[i + 1]]\n",
    "                if is_hydrogen_bond(res_i, res_jp1, j + 1, residue_keys, residues_dict) and \\\n",
    "                   is_hydrogen_bond(res_j, res_ip1, i + 1, residue_keys, residues_dict):\n",
    "                    bridges[(residue_keys[i], residue_keys[j])] = 'parallel'\n",
    "    return bridges\n",
    "\n",
    "\n",
    "def annotate_beta_strands_on_sequence(residues_dict, bridges):\n",
    "    \"\"\"\n",
    "    Assign 'E' to residues involved in beta strands based on detected bridges.\n",
    "    \"\"\"\n",
    "    residue_keys = sorted(residues_dict.keys())\n",
    "    n = len(residue_keys)\n",
    "    ss_seq = ['-' for _ in residue_keys]\n",
    "\n",
    "    for (res1, res2), _ in bridges.items():\n",
    "        if res1 in residue_keys:\n",
    "            ss_seq[residue_keys.index(res1)] = 'E'\n",
    "        if res2 in residue_keys:\n",
    "            ss_seq[residue_keys.index(res2)] = 'E'\n",
    "\n",
    "    # Fill in gaps within E regions (extend strands)\n",
    "    for i in range(1, n - 1):\n",
    "        if ss_seq[i - 1] == 'E' and ss_seq[i + 1] == 'E' and ss_seq[i] == '-':\n",
    "            ss_seq[i] = 'E'\n",
    "\n",
    "    # Remove isolated 'E's\n",
    "    for i in range(n):\n",
    "        if ss_seq[i] == 'E':\n",
    "            prev_is_E = (i > 0 and ss_seq[i - 1] == 'E')\n",
    "            next_is_E = (i < n - 1 and ss_seq[i + 1] == 'E')\n",
    "            if not prev_is_E and not next_is_E:\n",
    "                ss_seq[i] = '-'\n",
    "\n",
    "    return list(zip(residue_keys, ss_seq))\n",
    "\n",
    "\n",
    "def assign(residues_dict):\n",
    "    \"\"\"\n",
    "    Detect helix types (3-10, alpha, pi) using hydrogen bond patterns (i to i+3, +4, +5).\n",
    "    Returns a one-hot encoded matrix for loop, helix, and strand.\n",
    "    \"\"\"\n",
    "    residue_keys = sorted(residues_dict.keys(), key=lambda x: (x[0], x[1]))\n",
    "    residues = [residues_dict[k] for k in residue_keys]\n",
    "    L = len(residues)\n",
    "    hbmap = np.zeros((L, L), dtype=bool)\n",
    "\n",
    "    # Fill hydrogen bond map\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if is_hydrogen_bond(residues[i], residues[j], j, residue_keys, residues_dict):\n",
    "                hbmap[i, j] = True\n",
    "\n",
    "    def pad(arr, pad_width):\n",
    "        return np.pad(arr, pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "    # Detect helices from diagonal HB patterns\n",
    "    turn3 = np.diagonal(hbmap, offset=3) > 0\n",
    "    turn4 = np.diagonal(hbmap, offset=4) > 0\n",
    "    turn5 = np.diagonal(hbmap, offset=5) > 0\n",
    "\n",
    "    h3 = pad(turn3[:-1] * turn3[1:], (1, 3))\n",
    "    h4 = pad(turn4[:-1] * turn4[1:], (1, 4))\n",
    "    h5 = pad(turn5[:-1] * turn5[1:], (1, 5))\n",
    "\n",
    "    helix4 = h4 + np.roll(h4, 1) + np.roll(h4, 2) + np.roll(h4, 3)\n",
    "    h3 = h3 * ~np.roll(helix4, -1) * ~helix4\n",
    "    h5 = h5 * ~np.roll(helix4, -1) * ~helix4\n",
    "\n",
    "    helix3 = h3 + np.roll(h3, 1) + np.roll(h3, 2)\n",
    "    helix5 = h5 + np.roll(h5, 1) + np.roll(h5, 2) + np.roll(h5, 3) + np.roll(h5, 4)\n",
    "\n",
    "    helix = (helix3 + helix4 + helix5) > 0\n",
    "    strand = np.zeros_like(helix, dtype=bool)\n",
    "    loop = (~helix) & (~strand)\n",
    "\n",
    "    onehot = np.stack([loop, helix, strand], axis=-1)\n",
    "    return onehot, residue_keys\n",
    "\n",
    "\n",
    "def combine_secondary_structure(residues_dict):\n",
    "    \"\"\"\n",
    "    Combine helix and beta strand assignments into a final label per residue.\n",
    "    Returns labeled residues and detected beta bridges.\n",
    "    \"\"\"\n",
    "    onehot_ss, residue_keys = assign(residues_dict)\n",
    "    bridges = find_beta_bridges(residues_dict)\n",
    "    annotated = dict(annotate_beta_strands_on_sequence(residues_dict, bridges))\n",
    "\n",
    "    combined = []\n",
    "    for key, ss in zip(residue_keys, onehot_ss):\n",
    "        label = 'L'  # Default: loop\n",
    "        if ss[1]: label = 'H'  # Helix\n",
    "        if annotated.get(key) == 'E': label = 'E'  # Strand\n",
    "        combined.append(f\"{key[0]}{key[1]}: {label}\")\n",
    "    return combined, bridges\n",
    "\n",
    "\n",
    "def print_beta_bridges(bridges):\n",
    "    \"\"\"\n",
    "    Print detected beta bridges with classification (parallel or antiparallel).\n",
    "    \"\"\"\n",
    "    print(\"\\nHydrogen bonds (detected beta bridges):\")\n",
    "    for (res1, res2), btype in bridges.items():\n",
    "        print(f\"  {btype.capitalize()} between {res1} and {res2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc1e59",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f58fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hydrogen bonds (detected beta bridges):\n",
      "\n",
      "Final secondary structure:\n",
      "A23: L\n",
      "A24: L\n",
      "A25: L\n",
      "A26: L\n",
      "A27: H\n",
      "A28: H\n",
      "A29: H\n",
      "A30: H\n",
      "A31: H\n",
      "A32: H\n",
      "A33: H\n",
      "A34: H\n",
      "A35: H\n",
      "A36: H\n",
      "A37: H\n",
      "A38: H\n",
      "A39: H\n",
      "A40: H\n",
      "A41: H\n",
      "A42: H\n",
      "A43: H\n",
      "A44: H\n",
      "A45: H\n",
      "A46: H\n",
      "A47: H\n",
      "A48: H\n",
      "A49: H\n",
      "A50: H\n",
      "A51: H\n",
      "A52: L\n",
      "A53: L\n",
      "A54: L\n",
      "A55: L\n",
      "A56: L\n",
      "A57: L\n",
      "A58: L\n",
      "A59: L\n",
      "A60: L\n",
      "A61: L\n",
      "A62: H\n",
      "A63: H\n",
      "A64: H\n",
      "A65: H\n",
      "A66: H\n",
      "A67: H\n",
      "A68: H\n",
      "A69: H\n",
      "A70: H\n",
      "A71: H\n",
      "A72: H\n",
      "A73: H\n",
      "A74: H\n",
      "A75: L\n",
      "A76: L\n",
      "A77: L\n",
      "A78: L\n",
      "A79: L\n",
      "A80: L\n",
      "A81: L\n",
      "A82: L\n",
      "A83: L\n",
      "A84: L\n",
      "A85: L\n",
      "A86: H\n",
      "A87: H\n",
      "A88: H\n",
      "A89: H\n",
      "A90: H\n",
      "A91: H\n",
      "A92: H\n",
      "A93: H\n",
      "A94: H\n",
      "A95: H\n",
      "A96: H\n",
      "A97: H\n",
      "A98: H\n",
      "A99: H\n",
      "A100: H\n",
      "A101: H\n",
      "A102: H\n",
      "A103: H\n",
      "A104: H\n",
      "A105: H\n",
      "A106: H\n",
      "A107: H\n",
      "A108: H\n",
      "A109: H\n",
      "A110: H\n",
      "A111: H\n",
      "A112: H\n",
      "A113: L\n",
      "A114: L\n",
      "A115: L\n",
      "A116: L\n",
      "A117: L\n",
      "A118: L\n",
      "A119: L\n",
      "B23: L\n",
      "B24: L\n",
      "B25: L\n",
      "B26: L\n",
      "B27: H\n",
      "B28: H\n",
      "B29: H\n",
      "B30: H\n",
      "B31: H\n",
      "B32: H\n",
      "B33: H\n",
      "B34: H\n",
      "B35: H\n",
      "B36: H\n",
      "B37: H\n",
      "B38: H\n",
      "B39: H\n",
      "B40: H\n",
      "B41: H\n",
      "B42: H\n",
      "B43: H\n",
      "B44: H\n",
      "B45: H\n",
      "B46: H\n",
      "B47: H\n",
      "B48: H\n",
      "B49: H\n",
      "B50: H\n",
      "B51: H\n",
      "B52: L\n",
      "B53: L\n",
      "B54: L\n",
      "B55: L\n",
      "B56: L\n",
      "B57: L\n",
      "B58: L\n",
      "B59: L\n",
      "B60: L\n",
      "B61: L\n",
      "B62: H\n",
      "B63: H\n",
      "B64: H\n",
      "B65: H\n",
      "B66: H\n",
      "B67: H\n",
      "B68: H\n",
      "B69: H\n",
      "B70: H\n",
      "B71: H\n",
      "B72: H\n",
      "B73: H\n",
      "B74: H\n",
      "B75: L\n",
      "B76: L\n",
      "B77: L\n",
      "B78: L\n",
      "B79: L\n",
      "B80: L\n",
      "B81: L\n",
      "B82: L\n",
      "B83: L\n",
      "B84: L\n",
      "B85: L\n",
      "B86: H\n",
      "B87: H\n",
      "B88: H\n",
      "B89: H\n",
      "B90: H\n",
      "B91: H\n",
      "B92: H\n",
      "B93: H\n",
      "B94: H\n",
      "B95: H\n",
      "B96: H\n",
      "B97: H\n",
      "B98: H\n",
      "B99: H\n",
      "B100: H\n",
      "B101: H\n",
      "B102: H\n",
      "B103: H\n",
      "B104: H\n",
      "B105: H\n",
      "B106: H\n",
      "B107: H\n",
      "B108: H\n",
      "B109: H\n",
      "B110: H\n",
      "B111: H\n",
      "B112: H\n",
      "B113: L\n",
      "B114: L\n",
      "B115: L\n",
      "B116: L\n",
      "B117: L\n",
      "B118: L\n",
      "B119: L\n",
      "C23: L\n",
      "C24: L\n",
      "C25: L\n",
      "C26: L\n",
      "C27: H\n",
      "C28: H\n",
      "C29: H\n",
      "C30: H\n",
      "C31: H\n",
      "C32: H\n",
      "C33: H\n",
      "C34: H\n",
      "C35: H\n",
      "C36: H\n",
      "C37: H\n",
      "C38: H\n",
      "C39: H\n",
      "C40: H\n",
      "C41: H\n",
      "C42: H\n",
      "C43: H\n",
      "C44: H\n",
      "C45: H\n",
      "C46: H\n",
      "C47: H\n",
      "C48: H\n",
      "C49: H\n",
      "C50: H\n",
      "C51: H\n",
      "C52: L\n",
      "C53: L\n",
      "C54: L\n",
      "C55: L\n",
      "C56: L\n",
      "C57: L\n",
      "C58: L\n",
      "C59: L\n",
      "C60: L\n",
      "C61: L\n",
      "C62: H\n",
      "C63: H\n",
      "C64: H\n",
      "C65: H\n",
      "C66: H\n",
      "C67: H\n",
      "C68: H\n",
      "C69: H\n",
      "C70: H\n",
      "C71: H\n",
      "C72: H\n",
      "C73: H\n",
      "C74: H\n",
      "C75: L\n",
      "C76: L\n",
      "C77: L\n",
      "C78: L\n",
      "C79: L\n",
      "C80: L\n",
      "C81: L\n",
      "C82: L\n",
      "C83: L\n",
      "C84: L\n",
      "C85: L\n",
      "C86: H\n",
      "C87: H\n",
      "C88: H\n",
      "C89: H\n",
      "C90: H\n",
      "C91: H\n",
      "C92: H\n",
      "C93: H\n",
      "C94: H\n",
      "C95: H\n",
      "C96: H\n",
      "C97: H\n",
      "C98: H\n",
      "C99: H\n",
      "C100: H\n",
      "C101: H\n",
      "C102: H\n",
      "C103: H\n",
      "C104: H\n",
      "C105: H\n",
      "C106: H\n",
      "C107: H\n",
      "C108: H\n",
      "C109: H\n",
      "C110: H\n",
      "C111: H\n",
      "C112: H\n",
      "C113: L\n",
      "C114: L\n",
      "C115: L\n",
      "C116: L\n",
      "C117: L\n",
      "C118: L\n",
      "C119: L\n",
      "D23: L\n",
      "D24: L\n",
      "D25: L\n",
      "D26: L\n",
      "D27: H\n",
      "D28: H\n",
      "D29: H\n",
      "D30: H\n",
      "D31: H\n",
      "D32: H\n",
      "D33: H\n",
      "D34: H\n",
      "D35: H\n",
      "D36: H\n",
      "D37: H\n",
      "D38: H\n",
      "D39: H\n",
      "D40: H\n",
      "D41: H\n",
      "D42: H\n",
      "D43: H\n",
      "D44: H\n",
      "D45: H\n",
      "D46: H\n",
      "D47: H\n",
      "D48: H\n",
      "D49: H\n",
      "D50: H\n",
      "D51: H\n",
      "D52: L\n",
      "D53: L\n",
      "D54: L\n",
      "D55: L\n",
      "D56: L\n",
      "D57: L\n",
      "D58: L\n",
      "D59: L\n",
      "D60: L\n",
      "D61: L\n",
      "D62: H\n",
      "D63: H\n",
      "D64: H\n",
      "D65: H\n",
      "D66: H\n",
      "D67: H\n",
      "D68: H\n",
      "D69: H\n",
      "D70: H\n",
      "D71: H\n",
      "D72: H\n",
      "D73: H\n",
      "D74: H\n",
      "D75: L\n",
      "D76: L\n",
      "D77: L\n",
      "D78: L\n",
      "D79: L\n",
      "D80: L\n",
      "D81: L\n",
      "D82: L\n",
      "D83: L\n",
      "D84: L\n",
      "D85: L\n",
      "D86: H\n",
      "D87: H\n",
      "D88: H\n",
      "D89: H\n",
      "D90: H\n",
      "D91: H\n",
      "D92: H\n",
      "D93: H\n",
      "D94: H\n",
      "D95: H\n",
      "D96: H\n",
      "D97: H\n",
      "D98: H\n",
      "D99: H\n",
      "D100: H\n",
      "D101: H\n",
      "D102: H\n",
      "D103: H\n",
      "D104: H\n",
      "D105: H\n",
      "D106: H\n",
      "D107: H\n",
      "D108: H\n",
      "D109: H\n",
      "D110: H\n",
      "D111: H\n",
      "D112: H\n",
      "D113: L\n",
      "D114: L\n",
      "D115: L\n",
      "D116: L\n",
      "D117: L\n",
      "D118: L\n",
      "D119: L\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pdb_path = \"1bl8.pdb\"\n",
    "    residues = parse_pdb_residues(pdb_path)\n",
    "    result, bridges = combine_secondary_structure(residues)\n",
    "\n",
    "    print_beta_bridges(bridges)\n",
    "    print(\"\\nFinal secondary structure:\")\n",
    "    for line in result:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab399050",
   "metadata": {},
   "source": [
    "Comparaison entre DSSP et notre projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d1f198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison with DSSP:\n",
      "  Residues compared: 643\n",
      "  Exact matches: 629\n",
      "  Prediction accuracy: 97.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcluzeau/miniconda3/envs/env_proj_court/lib/python3.12/site-packages/MDAnalysis/analysis/base.py:542: UserWarning: Reader has no dt information, set to 1.0 ps\n",
      "  self.times[idx] = ts.time\n"
     ]
    }
   ],
   "source": [
    "def get_dssp_secondary_structure(pdb_path):\n",
    "    \"\"\"\n",
    "    Use DSSP via MDAnalysis to extract secondary structure from a PDB file.\n",
    "    Maps each residue to one of three classes: H (helix), E (strand), L (loop).\n",
    "    \"\"\"\n",
    "    u = mda.Universe(pdb_path)\n",
    "    dssp = DSSP(u).run()\n",
    "\n",
    "    dssp_dict = {}\n",
    "    # Extract residue identifiers and chains\n",
    "    resids = [res.resid for res in u.residues]\n",
    "    chains = [res.segid.strip() or res.atoms[0].chainID for res in u.residues]\n",
    "    sec_struct = dssp.results.dssp[0]  # DSSP returns a string of secondary structure labels\n",
    "\n",
    "    # Convert DSSP symbols to simplified labels: H (helix), E (strand), L (loop/other)\n",
    "    for resid, chain, ss in zip(resids, chains, sec_struct):\n",
    "        label = ss if ss in ['H', 'E'] else 'L'\n",
    "        dssp_dict[(chain, resid)] = label\n",
    "    return dssp_dict\n",
    "\n",
    "\n",
    "def get_prediction_dict(custom_result):\n",
    "    \"\"\"\n",
    "    Convert custom prediction output (e.g., ['A12: H', 'A13: L']) into a dictionary.\n",
    "    Keys are (chain, residue_id), values are secondary structure labels.\n",
    "    \"\"\"\n",
    "    pred_dict = {}\n",
    "    for entry in custom_result:\n",
    "        chain_res, label = entry.split(':')\n",
    "        chain = chain_res[0]  # First character is the chain\n",
    "        resnum = int(chain_res[1:])  # Rest is the residue number\n",
    "        pred_dict[(chain, resnum)] = label.strip()\n",
    "    return pred_dict\n",
    "\n",
    "\n",
    "def compare_structures(predicted, reference):\n",
    "    \"\"\"\n",
    "    Compare predicted secondary structure against a reference (e.g. DSSP).\n",
    "    Returns prediction accuracy as a percentage.\n",
    "    \"\"\"\n",
    "    matched = 0\n",
    "    total = 0\n",
    "\n",
    "    # Compare labels for each residue in the reference\n",
    "    for key, ref_ss in reference.items():\n",
    "        if key in predicted:\n",
    "            total += 1\n",
    "            if predicted[key] == ref_ss:\n",
    "                matched += 1\n",
    "\n",
    "    accuracy = 100 * matched / total if total else 0\n",
    "    return accuracy, matched, total\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdb_path = \"1f88.pdb\"\n",
    "\n",
    "    # Run custom secondary structure predictor\n",
    "    residues = parse_pdb_residues(pdb_path)\n",
    "    custom_result, _ = combine_secondary_structure(residues)\n",
    "    predicted = get_prediction_dict(custom_result)\n",
    "\n",
    "    # Run DSSP as reference standard\n",
    "    reference = get_dssp_secondary_structure(pdb_path)\n",
    "\n",
    "    # Compare custom prediction with DSSP results\n",
    "    accuracy, matched, total = compare_structures(predicted, reference)\n",
    "\n",
    "    print(\"\\nComparison with DSSP:\")\n",
    "    print(f\"  Residues compared: {total}\")\n",
    "    print(f\"  Exact matches: {matched}\")\n",
    "    print(f\"  Prediction accuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_proj_court",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
